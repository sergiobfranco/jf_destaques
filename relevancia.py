import requests
import pandas as pd
import os
import configparser
import traceback

from dotenv import load_dotenv

def obter_chave_deepseek():
    # Caminho absoluto do .env com base no local do script
    #base_dir = os.path.dirname(os.path.abspath(__file__))
    #env_path = os.path.join(base_dir, ".env")
    #load_dotenv(env_path)

    load_dotenv()

    # Caminho correto para o config_usuario.ini em dados/config/
    config_path = os.path.join("dados", "config", "config_usuario.ini")

    # Debug opcional
    print(f"üõ†Ô∏è Lendo config de: {config_path}")

    config = configparser.ConfigParser()
    config.read(config_path, encoding="utf-8")
    perfil = config.get("usuario", "perfil", fallback="client").strip().lower()

    env_var = f"DEEPSEEK_API_KEY_{perfil.upper()}"
    chave = os.getenv(env_var)

    # Diagn√≥stico
    print(f"Perfil de usu√°rio: {perfil}")
    print(f"Vari√°vel de ambiente esperada: {env_var}")
    print(f"Chave encontrada: {chave[:10]}..." if chave else "‚ùå Nenhuma chave encontrada")
    # Diagn√≥stico adicional opcional
    # traceback.print_stack(limit=2)

    if not chave:
        raise ValueError(f"Chave de API n√£o encontrada para o perfil '{perfil}' ({env_var}) no arquivo .env")
    
    return chave

from config import DEEPSEEK_API_URL

def avaliar_relevancia(df):
    PROMPT_CHARACTER_LIMIT = 30000

    #arq_api = 'api/Favoritos_Marcas_small.xlsx'
    #darq_relevancia_irrelevantes = 'api/Favoritos_Marcas_Irrelevantes.xlsx' # Esta vari√°vel n√£o ser√° mais usada para salvar o arquivo
    #arq_prompts = 'marca_setor/Prompts_Resumo_Noticias_DBSCAN.xlsx'

    api_key = obter_chave_deepseek()

    HEADERS = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"
    }

    # Carregamento inicial
    #df = pd.read_excel(arq_api)
    df['TextoCompleto'] = df['Titulo'].fillna('') + '. ' + df['Conteudo'].fillna('')
    marcas = df['Canais'].dropna().unique()

    # Fun√ß√£o para avaliar se a marca √© relevante na not√≠cia
    def avaliar_relevancia_marca(marca, texto):
        prompt = (
            f"Avalie a relev√¢ncia da marca \"{marca}\" na seguinte not√≠cia.\n\n"
            "A marca deve ser considerada relevante quando influencia ou √© influenciada pelos fatos descritos no texto, mesmo que de forma indireta ou moderada. "
            "Caso contr√°rio, se a marca for apenas citada superficialmente, sem v√≠nculo com os eventos principais, considere irrelevante.\n\n"
            "Responda apenas com 'True' (se for relevante) ou 'False' (se n√£o for relevante).\n\n"
            f"Texto:\n{texto}"
        )

        data = {
            "model": "deepseek-chat",
            "messages": [
                {"role": "user", "content": prompt}
            ],
            "temperature": 0,
            "max_tokens": 10
        }

        try:
            print(f"Enviando requisi√ß√£o ao DeepSeek para avaliar a marca '{marca}'...")
            response = requests.post(DEEPSEEK_API_URL, headers=HEADERS, json=data)
            response.raise_for_status()
            resposta = response.json()["choices"][0]["message"]["content"].strip()
            print(f"Resposta do DeepSeek: {resposta}")
            return resposta.lower().startswith("true")
        except Exception as e:
            print(f"Erro ao avaliar relev√¢ncia: {e}")
            return True  # Em caso de erro, assume como relevante para n√£o perder

    # Avalia relev√¢ncia se ainda n√£o tiver sido feito
    if 'RelevanciaMarca' not in df.columns or df['RelevanciaMarca'].isnull().all():
        print("Avaliando relev√¢ncia da marca nas not√≠cias...")
        df['RelevanciaMarca'] = df.apply(lambda row: avaliar_relevancia_marca(row['Canais'], row['TextoCompleto']), axis=1)

        # --- In√≠cio do ajuste para remover duplicatas relevantes ---
        # Define a ordem de prioridade das marcas
        # Removed duplicate 'Eldorado' from the list
        marca_order = ['JBS', 'J&F', 'PicPay', 'Eldorado', 'Joesley Batista', 'Wesley Batista', 'Banco Original']

        # Cria uma coluna tempor√°ria para ordena√ß√£o personalizada
        df['Marca_Order'] = pd.Categorical(df['Canais'], categories=marca_order, ordered=True)

        # Filtra apenas as not√≠cias relevantes (RelevanciaMarca == True) para aplicar a l√≥gica de desduplica√ß√£o
        df_relevantes = df[df['RelevanciaMarca'] == True].copy()

        # Ordena por Id e pela ordem de prioridade das marcas
        # Para IDs duplicados, a linha com a marca de maior prioridade (menor valor na categoria) vir√° primeiro
        df_relevantes_sorted = df_relevantes.sort_values(by=['Id', 'Marca_Order'], ascending=[True, True])

        # Remove duplicatas de Id, mantendo a primeira ocorr√™ncia (que ser√° a de maior prioridade devido √† ordena√ß√£o)
        df_relevantes_deduplicadas = df_relevantes_sorted.drop_duplicates(subset='Id', keep='first')

        # Remove a coluna tempor√°ria de ordena√ß√£o
        df_relevantes_deduplicadas = df_relevantes_deduplicadas.drop(columns=['Marca_Order'])

        # Separa as not√≠cias irrelevantes do DataFrame original
        df_irrelevantes = df[df['RelevanciaMarca'] == False].copy()

        # Remove a coluna tempor√°ria de ordena√ß√£o das irrelevantes tamb√©m
        df_irrelevantes = df_irrelevantes.drop(columns=['Marca_Order'])


        # Concatena as not√≠cias relevantes deduplicadas com as irrelevantes
        # A ordem das linhas n√£o √© garantida ap√≥s a concatena√ß√£o, mas as linhas corretas foram mantidas.
        # Se a ordem original for importante, pode ser necess√°rio um passo adicional para reordenar.
        df_final_relevancia = pd.concat([df_relevantes_deduplicadas, df_irrelevantes], ignore_index=True)

        # --- NOVO PASSO: Remover not√≠cias irrelevantes de df_final_relevancia ---
        print("Removendo not√≠cias irrelevantes de df_final_relevancia...")
        df_final_relevancia = df_final_relevancia[df_final_relevancia['RelevanciaMarca'] == True].copy()
        print(f"df_final_relevancia agora cont√©m {len(df_final_relevancia)} not√≠cias relevantes.")
        # --- FIM NOVO PASSO ---


        # Salva o DataFrame final (agora apenas relevantes) no arquivo de relev√¢ncia
        #df_final_relevancia.to_excel("api/Favoritos_Marcas_Relevancia.xlsx", index=False)
        #print("Arquivo api/Favoritos_Marcas_Relevancia.xlsx salvo (cont√©m apenas not√≠cias relevantes).")

        # --- Novo: Remover registros de final_df_small_marca que n√£o est√£o em df_final_relevancia (Id e Canais) ---
        # Carregar final_df_small_marca para processamento
        #final_df_small_marca = pd.read_excel(arq_api)
        final_df_small_marca = df

        # Criar um conjunto de tuplas (Id, Canais) das not√≠cias que devem ser MANTIDAS (usando o df_final_relevancia j√° filtrado)
        ids_canais_to_keep = set(zip(df_final_relevancia['Id'], df_final_relevancia['Canais']))

        # Filtrar final_df_small_marca para manter apenas as linhas cujos (Id, Canais) est√£o no conjunto
        # Ensure 'Canais' is treated as string in both DFs for consistent comparison
        final_df_small_marca['Canais'] = final_df_small_marca['Canais'].astype(str)
        df_final_relevancia['Canais'] = df_final_relevancia['Canais'].astype(str)

        ids_canais_to_keep = set(zip(df_final_relevancia['Id'], df_final_relevancia['Canais']))

        # Apply the filter
        final_df_small_marca_processed = final_df_small_marca[
            final_df_small_marca.apply(lambda row: (row['Id'], row['Canais']) in ids_canais_to_keep, axis=1)
        ].copy()

        return final_df_small_marca_processed, df_irrelevantes

        # Sobrescrever o arquivo Favoritos_Marcas_small.xlsx
        #final_df_small_marca_processed.to_excel(arq_api, index=False)
        #print(f"Arquivo {arq_api} sobrescrito ap√≥s remo√ß√£o de registros que n√£o foram considerados relevantes/priorit√°rios.")

        # --- Fim do novo ajuste ---


    else:
        print("Coluna RelevanciaMarca j√° presente.")
        # Se a coluna j√° existe, mas o usu√°rio quer aplicar a desduplica√ß√£o,
        # voc√™ pode adicionar a l√≥gica de desduplica√ß√£o aqui tamb√©m,
        # lendo o arquivo existente e re-salvando ap√≥s a desduplica√ß√£o.
        # Por simplicidade nesta resposta, apenas imprimimos a mensagem.
        # Para um comportamento mais robusto, a l√≥gica de desduplica√ß√£o
        # poderia ser aplicada sempre, ou ter uma flag para control√°-la.
        # Como a coluna RelevanciaMarca j√° existe, vamos carregar o df
        # e aplicar a l√≥gica de desduplica√ß√£o para garantir que o arquivo
        # de relev√¢ncia esteja correto para as pr√≥ximas etapas.

        print("Aplicando desduplica√ß√£o em not√≠cias relevantes do arquivo existente...")
        # Removed duplicate 'Eldorado' from the list
        marca_order = ['JBS', 'J&F', 'PicPay', 'Eldorado', 'Joesley Batista', 'Wesley Batista', 'Banco Original']
        df['Marca_Order'] = pd.Categorical(df['Canais'], categories=marca_order, ordered=True)
        df_relevantes = df[df['RelevanciaMarca'] == True].copy()
        df_relevantes_sorted = df_relevantes.sort_values(by=['Id', 'Marca_Order'], ascending=[True, True])
        df_relevantes_deduplicadas = df_relevantes_sorted.drop_duplicates(subset='Id', keep='first')
        df_relevantes_deduplicadas = df_relevantes_deduplicadas.drop(columns=['Marca_Order'])

        df_irrelevantes = df[df['RelevanciaMarca'] == False].copy()
        df_irrelevantes = df_irrelevantes.drop(columns=['Marca_Order']) # Remove se existia antes ou foi criada

        df_final_relevancia = pd.concat([df_relevantes_deduplicadas, df_irrelevantes], ignore_index=True)

        # --- NOVO PASSO: Remover not√≠cias irrelevantes de df_final_relevancia (no bloco else) ---
        print("Removendo not√≠cias irrelevantes de df_final_relevancia (no bloco else)...")
        df_final_relevancia = df_final_relevancia[df_final_relevancia['RelevanciaMarca'] == True].copy()
        print(f"df_final_relevancia agora cont√©m {len(df_final_relevancia)} not√≠cias relevantes (no bloco else).")
        # --- FIM NOVO PASSO ---

        df_final_relevancia.to_excel("api/Favoritos_Marcas_Relevancia.xlsx", index=False)
        print("Arquivo api/Favoritos_Marcas_Relevancia.xlsx re-salvo ap√≥s desduplica√ß√£o (cont√©m apenas not√≠cias relevantes).")

        # --- Novo: Remover registros de final_df_small_marca que n√£o est√£o em df_final_relevancia (Id e Canais) (caso a coluna j√° existisse) ---
        # Carregar final_df_small_marca para processamento
        #final_df_small_marca = pd.read_excel(arq_api)
        final_df_small_marca = df

        # Criar um conjunto de tuplas (Id, Canais) das not√≠cias que devem ser MANTIDAS (usando o df_final_relevancia j√° filtrado)
        # Ensure 'Canais' is treated as string in both DFs for consistent comparison
        final_df_small_marca['Canais'] = final_df_small_marca['Canais'].astype(str)
        df_final_relevancia['Canais'] = df_final_relevancia['Canais'].astype(str)

        ids_canais_to_keep = set(zip(df_final_relevancia['Id'], df_final_relevancia['Canais']))

        # Apply the filter
        final_df_small_marca_processed = final_df_small_marca[
            final_df_small_marca.apply(lambda row: (row['Id'], row['Canais']) in ids_canais_to_keep, axis=1)
        ].copy()

        # Sobrescrever o arquivo Favoritos_Marcas_small.xlsx
        #final_df_small_marca_processed.to_excel(arq_api, index=False)
        print(f"Arquivo {arq_api} sobrescrito ap√≥s remo√ß√£o de registros que n√£o foram considerados relevantes/priorit√°rios (coluna RelevanciaMarca j√° existia).")
        
        return final_df_small_marca_processed
        # --- Fim do novo ajuste (caso a coluna j√° existisse) ---


    # --- Fim do ajuste para remover duplicatas relevantes ---
