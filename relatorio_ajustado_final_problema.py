import os
import re
import shutil
from annotated_types import doc
from docx import Document
from googleapiclient.discovery import build
from googleapiclient.http import MediaFileUpload
from google.oauth2 import service_account
from datetime import datetime
from docx.oxml.shared import OxmlElement
from docx.oxml.ns import qn

def _limpar_paragrafo(paragraph):
    # remove todos os runs atuais
    for r in paragraph.runs[::-1]:
        paragraph._p.remove(r._element)

# Fun√ß√£o para upload no Google Drive
def upload_para_google_drive(caminho_arquivo, nome_arquivo, pasta_id):
    from google.oauth2 import service_account
    from googleapiclient.discovery import build
    from googleapiclient.http import MediaFileUpload

    SERVICE_ACCOUNT_FILE = 'service_account.json'
    SCOPES = ['https://www.googleapis.com/auth/drive']

    creds = service_account.Credentials.from_service_account_file(
        SERVICE_ACCOUNT_FILE, scopes=SCOPES
    )

    service = build('drive', 'v3', credentials=creds)

    file_metadata = {
        'name': nome_arquivo,
        'parents': [pasta_id]
    }

    media = MediaFileUpload(caminho_arquivo, mimetype='application/vnd.openxmlformats-officedocument.wordprocessingml.document')

    uploaded_file = service.files().create(
        body=file_metadata,
        media_body=media,
        fields='id',
        supportsAllDrives=True  # ‚úÖ ESSENCIAL para pastas compartilhadas
    ).execute()

    print(f"‚úÖ Upload conclu√≠do com ID: {uploaded_file.get('id')}")

def adicionar_hyperlink(paragraph, url, texto_display):
    """
    Adiciona um hyperlink a um par√°grafo no documento Word
    """
    # Criar o elemento hyperlink
    hyperlink = OxmlElement('w:hyperlink')
    hyperlink.set(qn('r:id'), paragraph.part.relate_to(url,
                                                       "http://schemas.openxmlformats.org/officeDocument/2006/relationships/hyperlink",
                                                       is_external=True))

    # Criar o run com o texto do link
    new_run = OxmlElement('w:r')

    # Configurar propriedades do texto (cor azul, sublinhado)
    rPr = OxmlElement('w:rPr')

    # Cor azul
    color = OxmlElement('w:color')
    color.set(qn('w:val'), '0000FF')
    rPr.append(color)

    # Sublinhado
    underline = OxmlElement('w:u')
    underline.set(qn('w:val'), 'single')
    rPr.append(underline)

    new_run.append(rPr)

    # Adicionar o texto
    new_run.text = texto_display
    hyperlink.append(new_run)

    return hyperlink

def processar_urls_em_paragrafo(paragraph):
    """
    VERS√ÉO CORRIGIDA - Processa um par√°grafo, convertendo URLs em hyperlinks
    mantendo a pontua√ß√£o original mas criando hyperlinks limpos
    """
    texto_completo = paragraph.text.strip()
    
    if not texto_completo:
        return False

    # ‚úÖ REGEX para encontrar URLs completas
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]]+(?:[^\s<>"{}|\\^`\[\]]*)'
    
    urls_encontradas = re.findall(padrao_url, texto_completo)

    if not urls_encontradas:
        return False

    # ‚úÖ NOVA ABORDAGEM: Processar URLs mantendo a pontua√ß√£o original
    urls_processadas = []
    for url in urls_encontradas:
        # Separar a URL limpa da pontua√ß√£o
        url_limpa = re.sub(r'[),;.:!?]+

def converter_urls_docx_para_hyperlinks(arquivo_entrada, pasta_destino='/app/output', pasta_id_drive=None):
    # 1Ô∏è‚É£ Validar se o arquivo existe
    if not os.path.exists(arquivo_entrada):
        print(f"‚ùå Erro: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        return False

    print(f"üìñ Abrindo arquivo: {arquivo_entrada}")
    doc = Document(arquivo_entrada)

    total_paragrafos_processados = 0
    total_urls_convertidas = 0

    # 2Ô∏è‚É£ Processar par√°grafos principais
    for i, p in enumerate(doc.paragraphs):
        if p.text.strip():
            urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
            if processar_urls_em_paragrafo(p):
                total_paragrafos_processados += 1
                total_urls_convertidas += urls_antes
                print(f"   ‚úÖ Par√°grafo {i+1} processado com {urls_antes} URLs")

    # 3Ô∏è‚É£ Processar tabelas
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    if p.text.strip():
                        urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
                        if processar_urls_em_paragrafo(p):
                            total_paragrafos_processados += 1
                            total_urls_convertidas += urls_antes

    # 4Ô∏è‚É£ Gerar nome do arquivo final
    nome_base = os.path.basename(arquivo_entrada).replace('.docx', '')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    arquivo_saida = os.path.join('output', f"{nome_base}_{timestamp}.docx")

    # 5Ô∏è‚É£ Salvar primeiro o arquivo localmente
    os.makedirs('output', exist_ok=True)
    doc.save(arquivo_saida)
    
    print(f"\nüìä Estat√≠sticas do processamento:")
    print(f"   - Par√°grafos processados: {total_paragrafos_processados}")
    print(f"   - URLs convertidas em hyperlinks: {total_urls_convertidas}")
    print(f"üíæ Arquivo salvo localmente: {arquivo_saida}")

    # 6Ô∏è‚É£ Upload para Google Drive, se configurado
    if pasta_id_drive:
        try:
            upload_para_google_drive(arquivo_saida, os.path.basename(arquivo_saida), pasta_id_drive)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

    # 7Ô∏è‚É£ Copiar para a pasta compartilhada do Docker (opcional)
    if os.path.isdir(pasta_destino):
        destino_drive = os.path.join(pasta_destino, os.path.basename(arquivo_saida))
        try:
            # Evita SameFileError quando origem e destino s√£o o mesmo arquivo
            if not (os.path.exists(destino_drive) and os.path.samefile(arquivo_saida, destino_drive)):
                shutil.copy2(arquivo_saida, destino_drive)
                print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
            else:
                print("‚ÑπÔ∏è Origem e destino s√£o o mesmo arquivo; c√≥pia ignorada.")
        except FileNotFoundError:
            # Alguns FS pedem que o diret√≥rio exista antes do samefile; garanta e copie
            os.makedirs(pasta_destino, exist_ok=True)
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
    else:
        print(f"‚ö†Ô∏è Pasta destino '{pasta_destino}' n√£o encontrada. Pulei a c√≥pia local.")

    return True

def metodo_alternativo_melhorado(arquivo_entrada, arquivo_saida):
    """
    M√©todo alternativo melhorado - substitui URLs por texto com formata√ß√£o
    """
    try:
        print(f"üìñ M√©todo alternativo melhorado - Abrindo arquivo: {arquivo_entrada}")
        doc = Document(arquivo_entrada)

        total_urls_encontradas = 0
        paragrafos_processados = 0

        # ‚úÖ Regex para capturar URLs completas
        padrao_url = r'https?://[^\s<>"{}|\\^`\[\]]+(?:[^\s<>"{}|\\^`\[\]]*)'

        # Processar par√°grafos
        for paragraph in doc.paragraphs:
            if not paragraph.text.strip():
                continue

            texto_original = paragraph.text
            urls_no_texto = re.findall(padrao_url, texto_original)
            
            # ‚úÖ Processar URLs mantendo pontua√ß√£o
            urls_processadas = []
            for url in urls_no_texto:
                url_limpa = re.sub(r'[),;.:!?]+

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Processar URLs mantendo pontua√ß√£o
                        urls_processadas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
        pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
        
        if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
            urls_processadas.append((url_limpa, pontuacao, url))

    if not urls_processadas:
        return False

    print(f"   üîó Encontradas {len(urls_processadas)} URLs: {[item[0] for item in urls_processadas[:2]]}{'...' if len(urls_processadas) > 2 else ''}")

    # Limpar o par√°grafo atual
    _limpar_paragrafo(paragraph)

    # ‚úÖ PROCESSAMENTO APRIMORADO: Manter pontua√ß√£o original
    texto_restante = texto_completo

    for url_limpa, pontuacao, url_original in urls_processadas:
        if url_original in texto_restante:
            # Dividir o texto pela URL original
            partes = texto_restante.split(url_original, 1)
            
            if len(partes) == 2:
                # Adicionar texto antes da URL (se houver)
                if partes[0]:
                    paragraph.add_run(partes[0])

                # ‚úÖ Criar hyperlink apenas com URL limpa
                hyperlink_element = adicionar_hyperlink(paragraph, url_limpa, url_limpa)
                paragraph._p.append(hyperlink_element)
                
                # ‚úÖ Adicionar a pontua√ß√£o como texto normal (n√£o hyperlink)
                if pontuacao:
                    paragraph.add_run(pontuacao)

                # Continuar com o resto do texto
                texto_restante = partes[1]

    # Adicionar texto restante ap√≥s a √∫ltima URL (se houver)
    if texto_restante:
        paragraph.add_run(texto_restante)

    return True

def converter_urls_docx_para_hyperlinks(arquivo_entrada, pasta_destino='/app/output', pasta_id_drive=None):
    # 1Ô∏è‚É£ Validar se o arquivo existe
    if not os.path.exists(arquivo_entrada):
        print(f"‚ùå Erro: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        return False

    print(f"üìñ Abrindo arquivo: {arquivo_entrada}")
    doc = Document(arquivo_entrada)

    total_paragrafos_processados = 0
    total_urls_convertidas = 0

    # 2Ô∏è‚É£ Processar par√°grafos principais
    for i, p in enumerate(doc.paragraphs):
        if p.text.strip():
            urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
            if processar_urls_em_paragrafo(p):
                total_paragrafos_processados += 1
                total_urls_convertidas += urls_antes
                print(f"   ‚úÖ Par√°grafo {i+1} processado com {urls_antes} URLs")

    # 3Ô∏è‚É£ Processar tabelas
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    if p.text.strip():
                        urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
                        if processar_urls_em_paragrafo(p):
                            total_paragrafos_processados += 1
                            total_urls_convertidas += urls_antes

    # 4Ô∏è‚É£ Gerar nome do arquivo final
    nome_base = os.path.basename(arquivo_entrada).replace('.docx', '')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    arquivo_saida = os.path.join('output', f"{nome_base}_{timestamp}.docx")

    # 5Ô∏è‚É£ Salvar primeiro o arquivo localmente
    os.makedirs('output', exist_ok=True)
    doc.save(arquivo_saida)
    
    print(f"\nüìä Estat√≠sticas do processamento:")
    print(f"   - Par√°grafos processados: {total_paragrafos_processados}")
    print(f"   - URLs convertidas em hyperlinks: {total_urls_convertidas}")
    print(f"üíæ Arquivo salvo localmente: {arquivo_saida}")

    # 6Ô∏è‚É£ Upload para Google Drive, se configurado
    if pasta_id_drive:
        try:
            upload_para_google_drive(arquivo_saida, os.path.basename(arquivo_saida), pasta_id_drive)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

    # 7Ô∏è‚É£ Copiar para a pasta compartilhada do Docker (opcional)
    if os.path.isdir(pasta_destino):
        destino_drive = os.path.join(pasta_destino, os.path.basename(arquivo_saida))
        try:
            # Evita SameFileError quando origem e destino s√£o o mesmo arquivo
            if not (os.path.exists(destino_drive) and os.path.samefile(arquivo_saida, destino_drive)):
                shutil.copy2(arquivo_saida, destino_drive)
                print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
            else:
                print("‚ÑπÔ∏è Origem e destino s√£o o mesmo arquivo; c√≥pia ignorada.")
        except FileNotFoundError:
            # Alguns FS pedem que o diret√≥rio exista antes do samefile; garanta e copie
            os.makedirs(pasta_destino, exist_ok=True)
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
    else:
        print(f"‚ö†Ô∏è Pasta destino '{pasta_destino}' n√£o encontrada. Pulei a c√≥pia local.")

    return True

def metodo_alternativo_melhorado(arquivo_entrada, arquivo_saida):
    """
    M√©todo alternativo melhorado - substitui URLs por texto com formata√ß√£o
    """
    try:
        print(f"üìñ M√©todo alternativo melhorado - Abrindo arquivo: {arquivo_entrada}")
        doc = Document(arquivo_entrada)

        total_urls_encontradas = 0
        paragrafos_processados = 0

        # ‚úÖ Regex corrigida para capturar URLs completas sem caracteres indesejados
        padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

        # Processar par√°grafos
        for paragraph in doc.paragraphs:
            if not paragraph.text.strip():
                continue

            texto_original = paragraph.text
            urls_no_texto = re.findall(padrao_url, texto_original)
            
            # ‚úÖ Limpeza das URLs encontradas
            urls_limpas = []
            for url in urls_no_texto:
                url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                if url_limpa and url_limpa not in urls_limpas:
                    urls_limpas.append(url_limpa)

            if urls_limpas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_limpas)} URLs encontradas")
                total_urls_encontradas += len(urls_limpas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa in urls_limpas:
                    # Procurar pela URL original no texto
                    padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                    match = re.search(padrao_busca, texto_restante)
                    
                    if match:
                        url_original = match.group()
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
                pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
                
                if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
                    urls_processadas.append((url_limpa, pontuacao, url))

            if urls_processadas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_processadas)} URLs encontradas")
                total_urls_encontradas += len(urls_processadas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa, pontuacao, url_original in urls_processadas:
                    if url_original in texto_restante:
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa no hyperlink
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))
                            
                            # ‚úÖ Adicionar pontua√ß√£o como texto normal
                            if pontuacao:
                                paragraph.add_run(pontuacao)

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
        pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
        
        if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
            urls_processadas.append((url_limpa, pontuacao, url))

    if not urls_processadas:
        return False

    print(f"   üîó Encontradas {len(urls_processadas)} URLs: {[item[0] for item in urls_processadas[:2]]}{'...' if len(urls_processadas) > 2 else ''}")

    # Limpar o par√°grafo atual
    _limpar_paragrafo(paragraph)

    # ‚úÖ PROCESSAMENTO APRIMORADO: Manter pontua√ß√£o original
    texto_restante = texto_completo

    for url_limpa, pontuacao, url_original in urls_processadas:
        if url_original in texto_restante:
            # Dividir o texto pela URL original
            partes = texto_restante.split(url_original, 1)
            
            if len(partes) == 2:
                # Adicionar texto antes da URL (se houver)
                if partes[0]:
                    paragraph.add_run(partes[0])

                # ‚úÖ Criar hyperlink apenas com URL limpa
                hyperlink_element = adicionar_hyperlink(paragraph, url_limpa, url_limpa)
                paragraph._p.append(hyperlink_element)
                
                # ‚úÖ Adicionar a pontua√ß√£o como texto normal (n√£o hyperlink)
                if pontuacao:
                    paragraph.add_run(pontuacao)

                # Continuar com o resto do texto
                texto_restante = partes[1]

    # Adicionar texto restante ap√≥s a √∫ltima URL (se houver)
    if texto_restante:
        paragraph.add_run(texto_restante)

    return True

def converter_urls_docx_para_hyperlinks(arquivo_entrada, pasta_destino='/app/output', pasta_id_drive=None):
    # 1Ô∏è‚É£ Validar se o arquivo existe
    if not os.path.exists(arquivo_entrada):
        print(f"‚ùå Erro: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        return False

    print(f"üìñ Abrindo arquivo: {arquivo_entrada}")
    doc = Document(arquivo_entrada)

    total_paragrafos_processados = 0
    total_urls_convertidas = 0

    # 2Ô∏è‚É£ Processar par√°grafos principais
    for i, p in enumerate(doc.paragraphs):
        if p.text.strip():
            urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
            if processar_urls_em_paragrafo(p):
                total_paragrafos_processados += 1
                total_urls_convertidas += urls_antes
                print(f"   ‚úÖ Par√°grafo {i+1} processado com {urls_antes} URLs")

    # 3Ô∏è‚É£ Processar tabelas
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    if p.text.strip():
                        urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
                        if processar_urls_em_paragrafo(p):
                            total_paragrafos_processados += 1
                            total_urls_convertidas += urls_antes

    # 4Ô∏è‚É£ Gerar nome do arquivo final
    nome_base = os.path.basename(arquivo_entrada).replace('.docx', '')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    arquivo_saida = os.path.join('output', f"{nome_base}_{timestamp}.docx")

    # 5Ô∏è‚É£ Salvar primeiro o arquivo localmente
    os.makedirs('output', exist_ok=True)
    doc.save(arquivo_saida)
    
    print(f"\nüìä Estat√≠sticas do processamento:")
    print(f"   - Par√°grafos processados: {total_paragrafos_processados}")
    print(f"   - URLs convertidas em hyperlinks: {total_urls_convertidas}")
    print(f"üíæ Arquivo salvo localmente: {arquivo_saida}")

    # 6Ô∏è‚É£ Upload para Google Drive, se configurado
    if pasta_id_drive:
        try:
            upload_para_google_drive(arquivo_saida, os.path.basename(arquivo_saida), pasta_id_drive)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

    # 7Ô∏è‚É£ Copiar para a pasta compartilhada do Docker (opcional)
    if os.path.isdir(pasta_destino):
        destino_drive = os.path.join(pasta_destino, os.path.basename(arquivo_saida))
        try:
            # Evita SameFileError quando origem e destino s√£o o mesmo arquivo
            if not (os.path.exists(destino_drive) and os.path.samefile(arquivo_saida, destino_drive)):
                shutil.copy2(arquivo_saida, destino_drive)
                print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
            else:
                print("‚ÑπÔ∏è Origem e destino s√£o o mesmo arquivo; c√≥pia ignorada.")
        except FileNotFoundError:
            # Alguns FS pedem que o diret√≥rio exista antes do samefile; garanta e copie
            os.makedirs(pasta_destino, exist_ok=True)
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
    else:
        print(f"‚ö†Ô∏è Pasta destino '{pasta_destino}' n√£o encontrada. Pulei a c√≥pia local.")

    return True

def metodo_alternativo_melhorado(arquivo_entrada, arquivo_saida):
    """
    M√©todo alternativo melhorado - substitui URLs por texto com formata√ß√£o
    """
    try:
        print(f"üìñ M√©todo alternativo melhorado - Abrindo arquivo: {arquivo_entrada}")
        doc = Document(arquivo_entrada)

        total_urls_encontradas = 0
        paragrafos_processados = 0

        # ‚úÖ Regex corrigida para capturar URLs completas sem caracteres indesejados
        padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

        # Processar par√°grafos
        for paragraph in doc.paragraphs:
            if not paragraph.text.strip():
                continue

            texto_original = paragraph.text
            urls_no_texto = re.findall(padrao_url, texto_original)
            
            # ‚úÖ Limpeza das URLs encontradas
            urls_limpas = []
            for url in urls_no_texto:
                url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                if url_limpa and url_limpa not in urls_limpas:
                    urls_limpas.append(url_limpa)

            if urls_limpas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_limpas)} URLs encontradas")
                total_urls_encontradas += len(urls_limpas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa in urls_limpas:
                    # Procurar pela URL original no texto
                    padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                    match = re.search(padrao_busca, texto_restante)
                    
                    if match:
                        url_original = match.group()
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
                            pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
                            
                            if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
                                urls_processadas.append((url_limpa, pontuacao, url))

                        if urls_processadas:
                            total_urls_encontradas += len(urls_processadas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa, pontuacao, url_original in urls_processadas:
                                if url_original in texto_restante:
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa no hyperlink
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))
                                        
                                        # ‚úÖ Adicionar pontua√ß√£o como texto normal
                                        if pontuacao:
                                            paragraph.add_run(pontuacao)

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
        pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
        
        if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
            urls_processadas.append((url_limpa, pontuacao, url))

    if not urls_processadas:
        return False

    print(f"   üîó Encontradas {len(urls_processadas)} URLs: {[item[0] for item in urls_processadas[:2]]}{'...' if len(urls_processadas) > 2 else ''}")

    # Limpar o par√°grafo atual
    _limpar_paragrafo(paragraph)

    # ‚úÖ PROCESSAMENTO APRIMORADO: Manter pontua√ß√£o original
    texto_restante = texto_completo

    for url_limpa, pontuacao, url_original in urls_processadas:
        if url_original in texto_restante:
            # Dividir o texto pela URL original
            partes = texto_restante.split(url_original, 1)
            
            if len(partes) == 2:
                # Adicionar texto antes da URL (se houver)
                if partes[0]:
                    paragraph.add_run(partes[0])

                # ‚úÖ Criar hyperlink apenas com URL limpa
                hyperlink_element = adicionar_hyperlink(paragraph, url_limpa, url_limpa)
                paragraph._p.append(hyperlink_element)
                
                # ‚úÖ Adicionar a pontua√ß√£o como texto normal (n√£o hyperlink)
                if pontuacao:
                    paragraph.add_run(pontuacao)

                # Continuar com o resto do texto
                texto_restante = partes[1]

    # Adicionar texto restante ap√≥s a √∫ltima URL (se houver)
    if texto_restante:
        paragraph.add_run(texto_restante)

    return True

def converter_urls_docx_para_hyperlinks(arquivo_entrada, pasta_destino='/app/output', pasta_id_drive=None):
    # 1Ô∏è‚É£ Validar se o arquivo existe
    if not os.path.exists(arquivo_entrada):
        print(f"‚ùå Erro: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        return False

    print(f"üìñ Abrindo arquivo: {arquivo_entrada}")
    doc = Document(arquivo_entrada)

    total_paragrafos_processados = 0
    total_urls_convertidas = 0

    # 2Ô∏è‚É£ Processar par√°grafos principais
    for i, p in enumerate(doc.paragraphs):
        if p.text.strip():
            urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
            if processar_urls_em_paragrafo(p):
                total_paragrafos_processados += 1
                total_urls_convertidas += urls_antes
                print(f"   ‚úÖ Par√°grafo {i+1} processado com {urls_antes} URLs")

    # 3Ô∏è‚É£ Processar tabelas
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    if p.text.strip():
                        urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
                        if processar_urls_em_paragrafo(p):
                            total_paragrafos_processados += 1
                            total_urls_convertidas += urls_antes

    # 4Ô∏è‚É£ Gerar nome do arquivo final
    nome_base = os.path.basename(arquivo_entrada).replace('.docx', '')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    arquivo_saida = os.path.join('output', f"{nome_base}_{timestamp}.docx")

    # 5Ô∏è‚É£ Salvar primeiro o arquivo localmente
    os.makedirs('output', exist_ok=True)
    doc.save(arquivo_saida)
    
    print(f"\nüìä Estat√≠sticas do processamento:")
    print(f"   - Par√°grafos processados: {total_paragrafos_processados}")
    print(f"   - URLs convertidas em hyperlinks: {total_urls_convertidas}")
    print(f"üíæ Arquivo salvo localmente: {arquivo_saida}")

    # 6Ô∏è‚É£ Upload para Google Drive, se configurado
    if pasta_id_drive:
        try:
            upload_para_google_drive(arquivo_saida, os.path.basename(arquivo_saida), pasta_id_drive)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

    # 7Ô∏è‚É£ Copiar para a pasta compartilhada do Docker (opcional)
    if os.path.isdir(pasta_destino):
        destino_drive = os.path.join(pasta_destino, os.path.basename(arquivo_saida))
        try:
            # Evita SameFileError quando origem e destino s√£o o mesmo arquivo
            if not (os.path.exists(destino_drive) and os.path.samefile(arquivo_saida, destino_drive)):
                shutil.copy2(arquivo_saida, destino_drive)
                print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
            else:
                print("‚ÑπÔ∏è Origem e destino s√£o o mesmo arquivo; c√≥pia ignorada.")
        except FileNotFoundError:
            # Alguns FS pedem que o diret√≥rio exista antes do samefile; garanta e copie
            os.makedirs(pasta_destino, exist_ok=True)
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
    else:
        print(f"‚ö†Ô∏è Pasta destino '{pasta_destino}' n√£o encontrada. Pulei a c√≥pia local.")

    return True

def metodo_alternativo_melhorado(arquivo_entrada, arquivo_saida):
    """
    M√©todo alternativo melhorado - substitui URLs por texto com formata√ß√£o
    """
    try:
        print(f"üìñ M√©todo alternativo melhorado - Abrindo arquivo: {arquivo_entrada}")
        doc = Document(arquivo_entrada)

        total_urls_encontradas = 0
        paragrafos_processados = 0

        # ‚úÖ Regex corrigida para capturar URLs completas sem caracteres indesejados
        padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

        # Processar par√°grafos
        for paragraph in doc.paragraphs:
            if not paragraph.text.strip():
                continue

            texto_original = paragraph.text
            urls_no_texto = re.findall(padrao_url, texto_original)
            
            # ‚úÖ Limpeza das URLs encontradas
            urls_limpas = []
            for url in urls_no_texto:
                url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                if url_limpa and url_limpa not in urls_limpas:
                    urls_limpas.append(url_limpa)

            if urls_limpas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_limpas)} URLs encontradas")
                total_urls_encontradas += len(urls_limpas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa in urls_limpas:
                    # Procurar pela URL original no texto
                    padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                    match = re.search(padrao_busca, texto_restante)
                    
                    if match:
                        url_original = match.group()
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
                pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
                
                if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
                    urls_processadas.append((url_limpa, pontuacao, url))

            if urls_processadas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_processadas)} URLs encontradas")
                total_urls_encontradas += len(urls_processadas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa, pontuacao, url_original in urls_processadas:
                    if url_original in texto_restante:
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa no hyperlink
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))
                            
                            # ‚úÖ Adicionar pontua√ß√£o como texto normal
                            if pontuacao:
                                paragraph.add_run(pontuacao)

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada."), '', url)
        pontuacao = url[len(url_limpa):] if len(url) > len(url_limpa) else ''
        
        if url_limpa and url_limpa not in [item[0] for item in urls_processadas]:
            urls_processadas.append((url_limpa, pontuacao, url))

    if not urls_processadas:
        return False

    print(f"   üîó Encontradas {len(urls_processadas)} URLs: {[item[0] for item in urls_processadas[:2]]}{'...' if len(urls_processadas) > 2 else ''}")

    # Limpar o par√°grafo atual
    _limpar_paragrafo(paragraph)

    # ‚úÖ PROCESSAMENTO APRIMORADO: Manter pontua√ß√£o original
    texto_restante = texto_completo

    for url_limpa, pontuacao, url_original in urls_processadas:
        if url_original in texto_restante:
            # Dividir o texto pela URL original
            partes = texto_restante.split(url_original, 1)
            
            if len(partes) == 2:
                # Adicionar texto antes da URL (se houver)
                if partes[0]:
                    paragraph.add_run(partes[0])

                # ‚úÖ Criar hyperlink apenas com URL limpa
                hyperlink_element = adicionar_hyperlink(paragraph, url_limpa, url_limpa)
                paragraph._p.append(hyperlink_element)
                
                # ‚úÖ Adicionar a pontua√ß√£o como texto normal (n√£o hyperlink)
                if pontuacao:
                    paragraph.add_run(pontuacao)

                # Continuar com o resto do texto
                texto_restante = partes[1]

    # Adicionar texto restante ap√≥s a √∫ltima URL (se houver)
    if texto_restante:
        paragraph.add_run(texto_restante)

    return True

def converter_urls_docx_para_hyperlinks(arquivo_entrada, pasta_destino='/app/output', pasta_id_drive=None):
    # 1Ô∏è‚É£ Validar se o arquivo existe
    if not os.path.exists(arquivo_entrada):
        print(f"‚ùå Erro: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        return False

    print(f"üìñ Abrindo arquivo: {arquivo_entrada}")
    doc = Document(arquivo_entrada)

    total_paragrafos_processados = 0
    total_urls_convertidas = 0

    # 2Ô∏è‚É£ Processar par√°grafos principais
    for i, p in enumerate(doc.paragraphs):
        if p.text.strip():
            urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
            if processar_urls_em_paragrafo(p):
                total_paragrafos_processados += 1
                total_urls_convertidas += urls_antes
                print(f"   ‚úÖ Par√°grafo {i+1} processado com {urls_antes} URLs")

    # 3Ô∏è‚É£ Processar tabelas
    for table in doc.tables:
        for row in table.rows:
            for cell in row.cells:
                for p in cell.paragraphs:
                    if p.text.strip():
                        urls_antes = len(re.findall(r'https?://[^\s]+', p.text))
                        if processar_urls_em_paragrafo(p):
                            total_paragrafos_processados += 1
                            total_urls_convertidas += urls_antes

    # 4Ô∏è‚É£ Gerar nome do arquivo final
    nome_base = os.path.basename(arquivo_entrada).replace('.docx', '')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M")
    arquivo_saida = os.path.join('output', f"{nome_base}_{timestamp}.docx")

    # 5Ô∏è‚É£ Salvar primeiro o arquivo localmente
    os.makedirs('output', exist_ok=True)
    doc.save(arquivo_saida)
    
    print(f"\nüìä Estat√≠sticas do processamento:")
    print(f"   - Par√°grafos processados: {total_paragrafos_processados}")
    print(f"   - URLs convertidas em hyperlinks: {total_urls_convertidas}")
    print(f"üíæ Arquivo salvo localmente: {arquivo_saida}")

    # 6Ô∏è‚É£ Upload para Google Drive, se configurado
    if pasta_id_drive:
        try:
            upload_para_google_drive(arquivo_saida, os.path.basename(arquivo_saida), pasta_id_drive)
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

    # 7Ô∏è‚É£ Copiar para a pasta compartilhada do Docker (opcional)
    if os.path.isdir(pasta_destino):
        destino_drive = os.path.join(pasta_destino, os.path.basename(arquivo_saida))
        try:
            # Evita SameFileError quando origem e destino s√£o o mesmo arquivo
            if not (os.path.exists(destino_drive) and os.path.samefile(arquivo_saida, destino_drive)):
                shutil.copy2(arquivo_saida, destino_drive)
                print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
            else:
                print("‚ÑπÔ∏è Origem e destino s√£o o mesmo arquivo; c√≥pia ignorada.")
        except FileNotFoundError:
            # Alguns FS pedem que o diret√≥rio exista antes do samefile; garanta e copie
            os.makedirs(pasta_destino, exist_ok=True)
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÇ Arquivo tamb√©m copiado para pasta compartilhada: {destino_drive}")
    else:
        print(f"‚ö†Ô∏è Pasta destino '{pasta_destino}' n√£o encontrada. Pulei a c√≥pia local.")

    return True

def metodo_alternativo_melhorado(arquivo_entrada, arquivo_saida):
    """
    M√©todo alternativo melhorado - substitui URLs por texto com formata√ß√£o
    """
    try:
        print(f"üìñ M√©todo alternativo melhorado - Abrindo arquivo: {arquivo_entrada}")
        doc = Document(arquivo_entrada)

        total_urls_encontradas = 0
        paragrafos_processados = 0

        # ‚úÖ Regex corrigida para capturar URLs completas sem caracteres indesejados
        padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

        # Processar par√°grafos
        for paragraph in doc.paragraphs:
            if not paragraph.text.strip():
                continue

            texto_original = paragraph.text
            urls_no_texto = re.findall(padrao_url, texto_original)
            
            # ‚úÖ Limpeza das URLs encontradas
            urls_limpas = []
            for url in urls_no_texto:
                url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                if url_limpa and url_limpa not in urls_limpas:
                    urls_limpas.append(url_limpa)

            if urls_limpas:
                print(f"   üîó Par√°grafo {paragrafos_processados + 1}: {len(urls_limpas)} URLs encontradas")
                total_urls_encontradas += len(urls_limpas)

                # Limpar o par√°grafo
                _limpar_paragrafo(paragraph)

                # Reconstruir o par√°grafo com formata√ß√£o
                texto_restante = texto_original

                for url_limpa in urls_limpas:
                    # Procurar pela URL original no texto
                    padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                    match = re.search(padrao_busca, texto_restante)
                    
                    if match:
                        url_original = match.group()
                        partes = texto_restante.split(url_original, 1)
                        
                        if len(partes) == 2:
                            # Adicionar texto antes da URL
                            if partes[0]:
                                paragraph.add_run(partes[0])

                            # ‚úÖ Usar URL limpa
                            paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                            # Continuar com o resto
                            texto_restante = partes[1]

                # Adicionar texto restante
                if texto_restante:
                    paragraph.add_run(texto_restante)

            paragrafos_processados += 1

        # Processar tabelas tamb√©m
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    for paragraph in cell.paragraphs:
                        if not paragraph.text.strip():
                            continue

                        texto_original = paragraph.text
                        urls_no_texto = re.findall(padrao_url, texto_original)
                        
                        # ‚úÖ Limpeza das URLs encontradas
                        urls_limpas = []
                        for url in urls_no_texto:
                            url_limpa = re.sub(r'[),;.:!?]+$', '', url)
                            if url_limpa and url_limpa not in urls_limpas:
                                urls_limpas.append(url_limpa)

                        if urls_limpas:
                            total_urls_encontradas += len(urls_limpas)
                            _limpar_paragrafo(paragraph)

                            texto_restante = texto_original
                            for url_limpa in urls_limpas:
                                padrao_busca = re.escape(url_limpa) + r'[),;.:!?]*'
                                match = re.search(padrao_busca, texto_restante)
                                
                                if match:
                                    url_original = match.group()
                                    partes = texto_restante.split(url_original, 1)
                                    
                                    if len(partes) == 2:
                                        if partes[0]:
                                            paragraph.add_run(partes[0])

                                        # ‚úÖ Usar URL limpa
                                        paragraph._p.append(adicionar_hyperlink(paragraph, url_limpa, url_limpa))

                                        texto_restante = partes[1]

                            if texto_restante:
                                paragraph.add_run(texto_restante)

        # Salvar documento
        doc.save(arquivo_saida)

        # Upload para Google Drive
        arquivo_local = arquivo_saida
        nome_arquivo = os.path.basename(arquivo_saida)
        try:
            upload_para_google_drive(arquivo_local, nome_arquivo, "1HCo8W9Q9ak8aKOmMRPhSyVBntCS_GD6J")        
        except Exception as e:
            print(f"‚ö†Ô∏è Erro no upload para Google Drive: {str(e)}")

        # Copiar para o Google Drive
        pasta_drive = r'/app/relatorios/'  # Altere para o caminho da sua pasta do Drive
        if os.path.isdir(pasta_drive):
            destino_drive = os.path.join(pasta_drive, os.path.basename(arquivo_saida))
            shutil.copy2(arquivo_saida, destino_drive)
            print(f"üìÅ Arquivo tamb√©m salvo em: {destino_drive}")
        else:
            print(f"‚ö†Ô∏è Pasta do Google Drive n√£o encontrada: {pasta_drive}")
            
        print(f"\n‚úÖ M√©todo alternativo conclu√≠do!")
        print(f"üìä Estat√≠sticas:")
        print(f"   - Par√°grafos processados: {paragrafos_processados}")
        print(f"   - Total de URLs formatadas: {total_urls_encontradas}")
        print(f"üíæ Arquivo salvo como: {arquivo_saida}")

        return True

    except Exception as e:
        print(f"‚ùå Erro no m√©todo alternativo: {str(e)}")
        return False

def testar_regex():
    """
    Fun√ß√£o para testar a regex com URLs de exemplo
    """
    print("üß™ Testando regex com URLs de exemplo...")

    # URLs de teste
    urls_teste = [
        "https://tinyurl.com/2aymnjlf",
        "https://www.google.com/search?q=python",
        "http://example.com/path/to/file.html",
        "https://github.com/user/repo#readme",
        "https://site.com/page?param1=value1&param2=value2"
    ]

    # Regex melhorada
    padrao_url = r'https?://[^\s<>"{}|\\^`\[\]\(\),;]+(?:[^\s<>"{}|\\^`\[\]\(\),;.])*'

    for url in urls_teste:
        match = re.search(padrao_url, url)
        if match:
            print(f"   ‚úÖ {url} -> Capturado: {match.group()}")
        else:
            print(f"   ‚ùå {url} -> N√£o capturado")

    print("\n" + "="*50)

def gerar_versao_ajustada(arquivo_preliminar, pasta_id_drive=None):
    """
    Aplica os ajustes finais ao relat√≥rio:
    - Converte URLs em hyperlinks
    - Gera nome do arquivo com timestamp
    - Salva localmente e realiza upload para o Google Drive (se configurado)
    """

    if not os.path.exists(arquivo_preliminar):
        print(f"‚ùå Arquivo n√£o encontrado: {arquivo_preliminar}")
        return

    print(f"üìñ Aplicando vers√£o ajustada com hyperlinks e timestamp...")
    
    # üß† Reaproveitar fun√ß√£o que j√° processa os hyperlinks e salva com timestamp
    sucesso = converter_urls_docx_para_hyperlinks(arquivo_preliminar, pasta_id_drive=pasta_id_drive)

    if sucesso:
        print("‚úÖ Vers√£o final ajustada com sucesso.")
    else:
        print("‚ùå Falha ao gerar a vers√£o ajustada.")