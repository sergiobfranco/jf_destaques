import streamlit as st
import os
import sys
from dotenv import load_dotenv

# Detectar base_dir mesmo dentro do .exe
if getattr(sys, 'frozen', False):
    base_dir = os.path.dirname(sys.executable)
else:
    base_dir = os.path.dirname(os.path.abspath(__file__))

env_path = os.path.join(base_dir, ".env")
load_dotenv(env_path)

import pandas as pd
import json
import requests
import time
from cronometro import obter_timestamp_brasilia, calcular_tempo_decorrido
from temporizador import aguardar_data_futura
from limpeza_marcas import limpar_marcas
from limpeza_setor import limpar_setor
from limpeza_editoriais import limpar_editoriais
from limpeza_specials import limpar_specials
from relevancia import avaliar_relevancia
from resumos_marcas_v2 import agrupar_noticias_por_similaridade
from prompts_setor import gerar_prompts_setor
from resumos_setor import gerar_resumos_setor
from relatorio_preliminar_segmentado import gerar_versao_preliminar
from relatorio_ajustado_final import gerar_versao_ajustada
from config import arq_api_original, arq_api, arq_api_irrelevantes, arq_results, arq_results_irrelevantes, arq_api_original_setor, arq_api_setor, arq_prompts_setor, \
    arq_results_setor, arq_api_original_editorial, arq_api_editorial, arq_api_original_SPECIALS, arq_api_SPECIALS, arq_resumo_final

# Vari√°vel global para armazenar a op√ß√£o selecionada
opcao_selecionada = None

def configurar_interface():
    """Configura a interface Streamlit"""
    st.set_page_config(
        page_title="Gerador de Relat√≥rios J&F",
        page_icon="üì∞",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title("üóûÔ∏è Gerador de Relat√≥rios J&F")
    st.markdown("---")

def selecionar_opcao():
    """Interface para sele√ß√£o do tipo de relat√≥rio"""
    global opcao_selecionada
    
    st.subheader("Selecione o tipo de relat√≥rio a ser gerado:")
    
    opcoes = {
        1: "üìä Relat√≥rio Completo",
        2: "üè¢ Somente Marcas",
        3: "üè≠ Somente Setor",
        4: "üì∞ Setor - Estad√£o",
        5: "üí∞ Setor - Valor Econ√¥mico",
        6: "üìÑ Setor - Folha de SP",
        7: "üåé Setor - O Globo",
        8: "‚ùå Sair da Aplica√ß√£o"
    }
    
    # Layout em colunas para melhor organiza√ß√£o
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Op√ß√µes Principais:**")
        for key in [1, 2, 3]:
            if st.button(opcoes[key], key=f"btn_{key}", use_container_width=True):
                opcao_selecionada = key
                st.session_state.opcao_selecionada = key
                st.rerun()
    
    with col2:
        st.write("**Op√ß√µes Espec√≠ficas de Ve√≠culos:**")
        for key in [4, 5, 6, 7]:
            if st.button(opcoes[key], key=f"btn_{key}", use_container_width=True):
                opcao_selecionada = key
                st.session_state.opcao_selecionada = key
                st.rerun()
    
    # Bot√£o de sair em linha separada para dar destaque
    st.markdown("---")
    col_exit = st.columns([2, 1, 2])[1]  # Centralizar o bot√£o
    with col_exit:
        if st.button(opcoes[8], key="btn_exit", type="secondary", use_container_width=True):
            st.session_state.opcao_selecionada = 8
            opcao_selecionada = 8
            st.rerun()
    
    # Verificar se a op√ß√£o de sair foi selecionada
    if 'opcao_selecionada' in st.session_state and st.session_state.opcao_selecionada == 8:
        st.error("üö™ Saindo da aplica√ß√£o...")
        st.info("Para fechar completamente, feche a aba do navegador ou pressione Ctrl+C no terminal.")
        st.stop()  # Para a execu√ß√£o do Streamlit
    
    # Mostrar op√ß√£o selecionada (exceto para sair)
    if 'opcao_selecionada' in st.session_state and st.session_state.opcao_selecionada != 8:
        opcao_selecionada = st.session_state.opcao_selecionada
        st.success(f"‚úÖ Op√ß√£o selecionada: **{opcoes[opcao_selecionada]}**")
        
        if st.button("üöÄ Iniciar Processamento", type="primary", use_container_width=True):
            return True
    
    return False

def abrir_arquivos_gerados():
    final_df = pd.read_excel(arq_api_original)
    final_df_small = pd.read_excel(arq_api)
    final_df_small_irrelevantes = pd.read_excel(arq_api_irrelevantes)
    df_resumos_marcas = pd.read_excel(arq_results)
    df_resumos_marcas_irrelevantes = pd.read_excel(arq_results_irrelevantes)
    final_df_setor = pd.read_excel(arq_api_original_setor)
    final_df_small_setor = pd.read_excel(arq_api_setor)
    df_resumos_setor = pd.read_excel(arq_results_setor)
    final_df_editoriais = pd.read_excel(arq_api_original_editorial)
    final_df_small_editoriais = pd.read_excel(arq_api_editorial)
    final_df_specials = pd.read_excel(arq_api_original_SPECIALS)
    final_df_small_specials = pd.read_excel(arq_api_SPECIALS)
    return (final_df, final_df_small, final_df_small_irrelevantes, df_resumos_marcas, df_resumos_marcas_irrelevantes,
        final_df_setor, final_df_small_setor, df_resumos_setor, final_df_editoriais, final_df_small_editoriais,
        final_df_specials, final_df_small_specials)

def carregar_configs(caminho_json):
    with open(caminho_json, 'r', encoding='utf-8') as f:
        return json.load(f)

def consultar_apis(configs, max_tentativas=3, timeout_base=30):
    """
    Consulta APIs com retry autom√°tico e timeouts progressivos
    Vers√£o simplificada sem depend√™ncias extras
    
    Args:
        configs: Lista de configura√ß√µes das APIs
        max_tentativas: N√∫mero m√°ximo de tentativas por API
        timeout_base: Timeout base em segundos
    """
    lista_df = []
    
    for i, config in enumerate(configs):
        url = config.get("url")
        data = config.get("data")
        st.info(f"Consultando API {i+1}/{len(configs)}: {url}")
        
        sucesso = False
        
        for tentativa in range(1, max_tentativas + 1):
            try:
                # Timeout progressivo: 30s, 60s, 90s
                timeout_atual = timeout_base + (tentativa - 1) * 30
                
                st.write(f"  Tentativa {tentativa}/{max_tentativas} (timeout: {timeout_atual}s)")
                
                response = requests.post(
                    url, 
                    json=data, 
                    timeout=timeout_atual
                )
                
                if response.status_code == 200:
                    dados = response.json()
                    df_api = pd.DataFrame(dados)
                    lista_df.append(df_api)
                    st.success(f"  ‚úÖ Sucesso: {len(df_api)} registros")
                    sucesso = True
                    break
                    
                elif response.status_code in [429, 500, 502, 503, 504]:
                    # C√≥digos que justificam retry
                    st.warning(f"  ‚ö†Ô∏è Status {response.status_code} - Tentativa {tentativa}")
                    if tentativa < max_tentativas:
                        espera = 5 + (tentativa * 2)  # 7s, 9s, 11s
                        st.write(f"  ‚è≥ Aguardando {espera}s...")
                        time.sleep(espera)
                else:
                    # Outros c√≥digos de erro - n√£o faz retry
                    st.error(f"  ‚ùå Erro {response.status_code} para URL: {url}")
                    break
                    
            except requests.exceptions.Timeout:
                st.warning(f"  ‚è±Ô∏è Timeout ap√≥s {timeout_atual}s na tentativa {tentativa}")
                if tentativa < max_tentativas:
                    espera = 10 * tentativa  # 10s, 20s, 30s
                    st.write(f"  ‚è≥ Aguardando {espera}s antes da pr√≥xima tentativa...")
                    time.sleep(espera)
                    
            except requests.exceptions.ConnectionError as e:
                erro_str = str(e)[:100]
                st.warning(f"  üîå Erro de conex√£o na tentativa {tentativa}: {erro_str}...")
                if tentativa < max_tentativas:
                    espera = 15 * tentativa  # 15s, 30s, 45s
                    st.write(f"  ‚è≥ Aguardando {espera}s antes da pr√≥xima tentativa...")
                    time.sleep(espera)
                    
            except requests.exceptions.RequestException as e:
                erro_str = str(e)[:100]
                st.error(f"  ‚ùå Erro de requisi√ß√£o na tentativa {tentativa}: {erro_str}...")
                if tentativa < max_tentativas:
                    time.sleep(5 * tentativa)
                    
            except Exception as e:
                erro_str = str(e)[:100]
                st.error(f"  ‚ùå Erro inesperado na tentativa {tentativa}: {erro_str}...")
                if tentativa < max_tentativas:
                    time.sleep(3 * tentativa)
        
        if not sucesso:
            st.error(f"  ‚ùå FALHA: Todas as {max_tentativas} tentativas falharam para {url}")
            st.warning(f"  ‚ö†Ô∏è Continuando com as pr√≥ximas APIs...")
    
    if lista_df:
        resultado = pd.concat(lista_df, ignore_index=True)
        st.success(f"\nüìä Total consolidado: {len(resultado)} registros de {len(lista_df)} APIs bem-sucedidas")
        return resultado
    else:
        st.warning(f"\n‚ö†Ô∏è Nenhuma API retornou dados v√°lidos")
        return pd.DataFrame()

def processar_relatorio():
    """Fun√ß√£o principal de processamento baseada na op√ß√£o selecionada"""
    global opcao_selecionada
    
    if 'opcao_selecionada' not in st.session_state:
        st.error("Nenhuma op√ß√£o foi selecionada!")
        return
    
    opcao_selecionada = st.session_state.opcao_selecionada

    # Mapear op√ß√µes para c√≥digos de ve√≠culo
    codigo_veiculo = None
    if opcao_selecionada == 4:  # Setor - Estad√£o
        codigo_veiculo = 675
    elif opcao_selecionada == 5:  # Setor - Valor Econ√¥mico
        codigo_veiculo = 10459
    elif opcao_selecionada == 6:  # Setor - Folha de SP
        codigo_veiculo = 331
    elif opcao_selecionada == 7:  # Setor - O Globo
        codigo_veiculo = 682

    # Pegar o timestamp atual em Bras√≠lia
    ts = obter_timestamp_brasilia()
    st.write("Timestamp atual:", ts)
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    try:
        # TODO: Aqui voc√™ implementar√° a l√≥gica condicional baseada na opcao_selecionada
        # Por enquanto, mantendo o processamento completo
        
        
        # Inicializar vari√°veis para controle de fluxo
        executar_marcas = opcao_selecionada in [1, 2]  # Relat√≥rio Completo ou Somente Marcas
        executar_setor = opcao_selecionada in [1, 3, 4, 5, 6, 7]  # Todas exceto Somente Marcas
        executar_editoriais = True  # Sempre executar
        executar_specials = True  # Sempre executar
        
        # Vari√°veis para armazenar dados processados
        final_df = pd.DataFrame()
        final_df_small = pd.DataFrame()
        final_df_small_irrelevantes = pd.DataFrame()
        df_resumos_marcas = pd.DataFrame()
        df_resumos_marcas_irrelevantes = pd.DataFrame()
        final_df_setor = pd.DataFrame()
        final_df_small_setor = pd.DataFrame()
        df_resumos_setor = pd.DataFrame()
        final_df_editoriais = pd.DataFrame()
        final_df_small_editoriais = pd.DataFrame()
        final_df_specials = pd.DataFrame()
        final_df_small_specials = pd.DataFrame()
        
        total_steps = 0
        current_step = 0
        
        # Calcular total de steps baseado na op√ß√£o
        if executar_marcas:
            total_steps += 4  # 2, 3, 4A, 4B
        if executar_setor:
            total_steps += 3  # 5, 6, 7
        total_steps += 4  # 8, 9, 10, 11 (sempre executados)
        
        # ===== PROCESSAMENTO DE MARCAS =====
        if executar_marcas:
            status_text.text("Iniciando processamento das APIs de MARCAS...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            # 2. Chamada de API de MARCAS
            caminho_json = "dados/config/api_marca_configs.json"
            configs = carregar_configs(caminho_json)
            marcas_df = consultar_apis(configs)

            if marcas_df.empty:
                st.warning("‚ö†Ô∏è ATEN√á√ÉO: Nenhum registro retornado pelas APIs de MARCAS!")
                st.info("üîç Criando DataFrame de MARCAS vazio com estrutura padr√£o...")
                colunas_marcas = [
                    'Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais'
                ]
                marcas_df = pd.DataFrame(columns=colunas_marcas)
                final_df = marcas_df.copy()
                final_df_small_bruto = marcas_df.copy()
                st.success("‚úÖ DataFrames vazios criados com sucesso para MARCAS")
            else:
                st.success(f"‚úÖ {len(marcas_df)} registros obtidos para MARCAS")
                final_df, final_df_small_bruto = limpar_marcas(marcas_df)

            final_df.to_excel(arq_api_original, index=False)
            
            # 3. Avalia√ß√£o de RELEV√ÇNCIA
            status_text.text("Processando avalia√ß√£o de relev√¢ncia...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            st.info(f"üìä final_df tem {len(final_df)} registros")
            st.info(f"üìä final_df_small_bruto tem {len(final_df_small_bruto)} registros")

            if marcas_df.empty:
                st.warning("‚ö†Ô∏è ATEN√á√ÉO: Nenhum registro retornado pelas APIs de MARCAS!")
                st.info("üîç Criando DataFrame de RELEV√ÇNCIA vazio com estrutura padr√£o...")
                colunas_relevancia = [
                    'Id', 'Titulo', 'Conteudo', 'IdVeiculo', 'Canais', 'TextoCompleto', 'RelevanciaMarca'
                ]
                relevancia_df = pd.DataFrame(columns=colunas_relevancia)
                final_df_small = relevancia_df.copy()
                final_df_small_irrelevantes = relevancia_df.copy()
                st.success("‚úÖ DataFrames vazios de RELEV√ÇNCIA criados com sucesso para MARCAS")
            else:
                final_df_small, final_df_small_irrelevantes = avaliar_relevancia(final_df_small_bruto)

            st.info(f"üìä final_df_small tem {len(final_df_small)} registros")
            st.info(f"üìä final_df_small_irrelevantes tem {len(final_df_small_irrelevantes)} registros")

            final_df_small.to_excel(arq_api, index=False)
            final_df_small_irrelevantes.to_excel(arq_api_irrelevantes, index=False)

            # 4.A Agrupa MARCAS por SIMILARIDADE e gera RESUMOS pelo DeepSeek - Not√≠cias Relevantes
            status_text.text("Agrupando not√≠cias relevantes por similaridade...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            if final_df_small.empty:
                colunas_resumos = [
                    'Marca', 'GrupoID', 'QtdNoticias', 'Ids', 'Resumo'
                ]
                df_resumos_marcas = pd.DataFrame(columns=colunas_resumos)
            else:
                df_resumos_marcas = agrupar_noticias_por_similaridade(final_df_small)

            st.info(f"üìä df_resumos_marcas resultante tem {len(df_resumos_marcas)} registros")
            df_resumos_marcas.to_excel(arq_results, index=False)

            # 4.B Agrupa MARCAS por SIMILARIDADE e gera RESUMOS pelo DeepSeek - Not√≠cias Irrelevantes
            status_text.text("Agrupando not√≠cias irrelevantes por similaridade...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            if final_df_small_irrelevantes.empty:
                colunas_resumos = [
                    'Marca', 'GrupoID', 'QtdNoticias', 'Ids', 'Resumo'
                ]
                df_resumos_marcas_irrelevantes = pd.DataFrame(columns=colunas_resumos)
            else:
                df_resumos_marcas_irrelevantes = agrupar_noticias_por_similaridade(final_df_small_irrelevantes)

            if df_resumos_marcas_irrelevantes is not None and not df_resumos_marcas_irrelevantes.empty:
                df_resumos_marcas_irrelevantes.to_excel(arq_results_irrelevantes, index=False)
            else:
                st.warning("‚ö†Ô∏è Nenhuma not√≠cia irrelevante encontrada. Gerando arquivo vazio com cabe√ßalho.")
                colunas = ["Marca", "GrupoID", "QtdNoticias", "Ids", "Resumo"]
                pd.DataFrame(columns=colunas).to_excel(arq_results_irrelevantes, index=False)
        else:
            # Criar DataFrames vazios para MARCAS quando n√£o processadas
            st.info("üìã Pulando processamento de MARCAS conforme op√ß√£o selecionada")
            colunas_marcas = ['Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais']
            colunas_relevancia = ['Id', 'Titulo', 'Conteudo', 'IdVeiculo', 'Canais', 'TextoCompleto', 'RelevanciaMarca']
            colunas_resumos = ['Marca', 'GrupoID', 'QtdNoticias', 'Ids', 'Resumo']
            
            final_df = pd.DataFrame(columns=colunas_marcas)
            final_df_small = pd.DataFrame(columns=colunas_relevancia)
            final_df_small_irrelevantes = pd.DataFrame(columns=colunas_relevancia)
            df_resumos_marcas = pd.DataFrame(columns=colunas_resumos)
            df_resumos_marcas_irrelevantes = pd.DataFrame(columns=colunas_resumos)
            
            # Salvar DataFrames vazios
            final_df.to_excel(arq_api_original, index=False)
            final_df_small.to_excel(arq_api, index=False)
            final_df_small_irrelevantes.to_excel(arq_api_irrelevantes, index=False)
            df_resumos_marcas.to_excel(arq_results, index=False)
            df_resumos_marcas_irrelevantes.to_excel(arq_results_irrelevantes, index=False)

        # ===== PROCESSAMENTO DE SETOR =====
        if executar_setor:
            # 5. Chamada de API de SETOR
            status_text.text("Processando APIs de SETOR...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            # Determinar o arquivo de configura√ß√£o baseado na op√ß√£o selecionada
            if codigo_veiculo:
                # Para op√ß√µes espec√≠ficas de ve√≠culos, usar arquivo dedicado
                caminho_json = f"dados/config/api_setor_{codigo_veiculo}_configs.json"
                st.info(f"üéØ Usando configura√ß√£o espec√≠fica para ve√≠culo {codigo_veiculo}: {caminho_json}")
            else:
                # Para "Somente Setor" ou "Relat√≥rio Completo", usar arquivo geral
                caminho_json = "dados/config/api_setor_configs.json"
                st.info(f"üìÅ Usando configura√ß√£o geral de setor: {caminho_json}")
            
            # Carregar configura√ß√µes do arquivo apropriado
            try:
                configs = carregar_configs(caminho_json)
                st.success(f"‚úÖ Carregadas {len(configs)} configura√ß√µes de {caminho_json}")
            except FileNotFoundError:
                st.error(f"‚ùå Arquivo de configura√ß√£o n√£o encontrado: {caminho_json}")
                configs = []
            except Exception as e:
                st.error(f"‚ùå Erro ao carregar configura√ß√µes de {caminho_json}: {str(e)}")
                configs = []
            
            setor_df = consultar_apis(configs)

            if setor_df.empty:
                st.warning("‚ö†Ô∏è ATEN√á√ÉO: Nenhum registro retornado pelas APIs de SETOR!")
                st.info("üîç Criando DataFrame de SETOR vazio com estrutura padr√£o...")
                colunas_setor = [
                    'Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais'
                ]
                setor_df = pd.DataFrame(columns=colunas_setor)
                final_df_setor = setor_df.copy()
                final_df_small_setor = setor_df.copy()
                st.success("‚úÖ DataFrames vazios criados com sucesso para SETOR")
            else:
                st.success(f"‚úÖ {len(setor_df)} registros obtidos para SETOR")
                final_df_setor, final_df_small_setor = limpar_setor(setor_df)

            final_df_setor.to_excel(arq_api_original_setor, index=False)
            final_df_small_setor.to_excel(arq_api_setor, index=False)

            # 6. Agrupa not√≠cias de SETOR por SIMILARIDADE e gera PROMPTS para resumos
            status_text.text("Gerando prompts para resumos de SETOR...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            if final_df_small_setor.empty:
                df_prompts_setor = pd.DataFrame(columns=['Id', 'Tipo', 'Prompt', 'Tema', 'RelevanceScore', 'IdVeiculo'])
            else:
                df_prompts_setor = gerar_prompts_setor(final_df_small_setor)
            df_prompts_setor.to_excel(arq_prompts_setor, index=False)

            # 7. Processa RESUMOS de not√≠cias de SETOR
            status_text.text("Processando resumos de SETOR...")
            current_step += 1
            progress_bar.progress(int((current_step / total_steps) * 90))
            
            if df_prompts_setor.empty:
                df_resumos_setor = pd.DataFrame(columns=['Tema', 'Id', 'Resumo'])
            else:
                df_resumos_setor = gerar_resumos_setor(df_prompts_setor)
            df_resumos_setor.to_excel(arq_results_setor, index=False)
        else:
            # Criar DataFrames vazios para SETOR quando n√£o processado
            st.info("üìã Pulando processamento de SETOR conforme op√ß√£o selecionada")
            colunas_setor = ['Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais']
            colunas_prompts = ['Id', 'Tipo', 'Prompt', 'Tema', 'RelevanceScore', 'IdVeiculo']
            colunas_resumos_setor = ['Tema', 'Id', 'Resumo']
            
            final_df_setor = pd.DataFrame(columns=colunas_setor)
            final_df_small_setor = pd.DataFrame(columns=colunas_setor)
            df_prompts_setor = pd.DataFrame(columns=colunas_prompts)
            df_resumos_setor = pd.DataFrame(columns=colunas_resumos_setor)
            
            # Salvar DataFrames vazios
            final_df_setor.to_excel(arq_api_original_setor, index=False)
            final_df_small_setor.to_excel(arq_api_setor, index=False)
            df_prompts_setor.to_excel(arq_prompts_setor, index=False)
            df_resumos_setor.to_excel(arq_results_setor, index=False)

        # ===== PROCESSAMENTO DE EDITORIAIS (SEMPRE EXECUTADO) =====
        # 8. Chamada de API de EDITORIAIS
        status_text.text("Processando APIs de EDITORIAIS...")
        current_step += 1
        progress_bar.progress(int((current_step / total_steps) * 90))
        
        caminho_json = "dados/config/api_editorial_configs.json"
        configs = carregar_configs(caminho_json)
        editoriais_df = consultar_apis(configs)

        if editoriais_df.empty:
            st.warning("‚ö†Ô∏è ATEN√á√ÉO: Nenhum registro retornado pelas APIs de EDITORIAIS!")
            st.info("üîç Criando DataFrame de EDITORIAIS vazio com estrutura padr√£o...")
            colunas_editoriais = [
                'Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais'
            ]
            editoriais_df = pd.DataFrame(columns=colunas_editoriais)
            final_df_editoriais = editoriais_df.copy()
            final_df_small_editoriais = editoriais_df.copy()
            st.success("‚úÖ DataFrames vazios criados com sucesso para EDITORIAIS")
        else:
            st.success(f"‚úÖ {len(editoriais_df)} registros obtidos para EDITORIAIS")
            final_df_editoriais, final_df_small_editoriais = limpar_editoriais(editoriais_df)

        final_df_editoriais.to_excel(arq_api_original_editorial, index=False)
        final_df_small_editoriais.to_excel(arq_api_editorial, index=False)

        # ===== PROCESSAMENTO DE SPECIALS (SEMPRE EXECUTADO) =====
        # 9. Chamada de API de SPECIALS
        status_text.text("Processando APIs de SPECIALS...")
        current_step += 1
        progress_bar.progress(int((current_step / total_steps) * 90))
        
        caminho_json = "dados/config/api_SPECIALS_configs.json"
        configs = carregar_configs(caminho_json)
        specials_df = consultar_apis(configs)

        if specials_df.empty:
            st.warning("‚ö†Ô∏è ATEN√á√ÉO: Nenhum registro retornado pelas APIs de SPECIALS!")
            st.info("üîç Criando DataFrame de SPECIALS vazio com estrutura padr√£o...")
            colunas_specials = [
                'Id', 'Titulo', 'Conteudo', 'UrlOriginal', 'DataVeiculacao', 'IdVeiculo', 'Canais'
            ]
            specials_df = pd.DataFrame(columns=colunas_specials)
            final_df_specials = specials_df.copy()
            final_df_small_specials = specials_df.copy()
            st.success("‚úÖ DataFrames vazios criados com sucesso para SPECIALS")
        else:
            st.success(f"‚úÖ {len(specials_df)} registros obtidos para SPECIALS")
            final_df_specials, final_df_small_specials = limpar_specials(specials_df)

        final_df_specials.to_excel(arq_api_original_SPECIALS, index=False)
        final_df_small_specials.to_excel(arq_api_SPECIALS, index=False)

        # ===== GERA√á√ÉO DOS RELAT√ìRIOS (SEMPRE EXECUTADO) =====
        # 10. Gera√ß√£o do RELAT√ìRIO DE DESTAQUES
        status_text.text("Gerando relat√≥rio de destaques...")
        current_step += 1
        progress_bar.progress(int((current_step / total_steps) * 90))
        
        # Preparar dados para merge se necess√°rio
        if not final_df_small.empty:
            try:
                df_short = pd.read_excel('dados/api/shorturls_por_id.xlsx')
                final_df_small['Id'] = final_df_small['Id'].astype(int)
                df_short['Id'] = df_short['Id'].astype(int)
                final_df_small = final_df_small.merge(df_short, on=['Id', 'Canais'], how='left')
            except FileNotFoundError:
                st.warning("‚ö†Ô∏è Arquivo shorturls_por_id.xlsx n√£o encontrado. Continuando sem merge.")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erro no merge com shorturls: {str(e)}")

        # Chamar gerar_versao_preliminar com par√¢metros
        gerar_versao_preliminar(
            final_df_small, 
            final_df_small_irrelevantes, 
            df_resumos_marcas, 
            df_resumos_marcas_irrelevantes, 
            final_df, 
            df_resumos_setor, 
            final_df_setor, 
            final_df_editoriais, 
            final_df_small_specials,
            opcao_selecionada=opcao_selecionada,
            codigo_veiculo=codigo_veiculo
        )
        
        # 11. Gera√ß√£o da Vers√£o Ajustada do RELAT√ìRIO DE DESTAQUES
        status_text.text("Gerando vers√£o ajustada do relat√≥rio...")
        current_step += 1
        progress_bar.progress(100)
        
        PASTA_ID_DRIVE = "1BdPoC3HZ7rIVd_0cgEVl4xGIjimVXTmq"
        gerar_versao_ajustada(arq_resumo_final, pasta_id_drive=PASTA_ID_DRIVE)

        status_text.text("Processamento conclu√≠do!")

        # Calcular o tempo decorrido desde aquele timestamp
        resultado = calcular_tempo_decorrido(ts)
        
        st.success("üéâ Processamento conclu√≠do com sucesso!")
        st.info(f"‚è±Ô∏è Tempo decorrido: {resultado['segundos']:.2f} segundos ({resultado['minutos']:.2f} minutos)")
        
        # Mostrar informa√ß√µes sobre a op√ß√£o selecionada
        opcoes_nomes = {
            1: "Relat√≥rio Completo",
            2: "Somente Marcas", 
            3: "Somente Setor",
            4: "Setor - Estad√£o",
            5: "Setor - Valor Econ√¥mico", 
            6: "Setor - Folha de SP",
            7: "Setor - O Globo"
        }
        
        info_opcao = f"üìã Op√ß√£o processada: **{opcoes_nomes[opcao_selecionada]}**"
        if codigo_veiculo:
            info_opcao += f" (C√≥digo do ve√≠culo: {codigo_veiculo})"
        
        st.info(info_opcao)
        
    except Exception as e:
        st.error(f"‚ùå Erro durante o processamento: {str(e)}")
        st.exception(e)

def main():
    """Fun√ß√£o principal com interface Streamlit"""
    configurar_interface()
    
    # Verificar se deve sair antes de mostrar a interface
    if 'opcao_selecionada' in st.session_state and st.session_state.opcao_selecionada == 8:
        st.error("üö™ Aplica√ß√£o encerrada pelo usu√°rio")
        st.info("Para reiniciar, recarregue a p√°gina ou execute novamente o script.")
        st.stop()
    
    # Interface de sele√ß√£o
    if selecionar_opcao():
        st.markdown("---")
        st.subheader("üìä Processamento em Andamento")
        processar_relatorio()

if __name__ == "__main__":
    main()